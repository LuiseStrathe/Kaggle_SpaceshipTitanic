{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle - Spaceship Titanic\n",
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "import os\n",
    "from os import path\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data for Training and Model Selection (Train & Validation & Test)\n",
    "\n",
    "TRAIN.SCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PassengerId  CryoSleep        Age       VIP  RoomService    FoodCourt  \\\n",
      "mean            inf   0.354139  28.828093  0.022968   222.822935   456.714705   \n",
      "std             NaN   0.478287  14.446399  0.149813   674.900407  1574.797221   \n",
      "median     461251.0   0.000000  27.000000  0.000000     0.000000     0.000000   \n",
      "\n",
      "        ShoppingMall          Spa       VRDeck  Transported    Spendings  \n",
      "mean      175.499043   315.693842   304.189769     0.503307  1480.307361  \n",
      "std       613.969158  1118.074541  1170.639327     0.500025  2816.389160  \n",
      "median      0.000000     0.000000     0.000000     1.000000   739.000000  \n"
     ]
    }
   ],
   "source": [
    "#import dataset\n",
    "X = pd.read_csv('../data/raw/train.csv')\n",
    "\n",
    "#split dataset into train and test\n",
    "X_train_input, X_test_input = train_test_split(X, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "#add spendings column\n",
    "'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'\n",
    "X_train_input['Spendings'] = X_train_input['RoomService'] + X_train_input['FoodCourt'] + X_train_input['ShoppingMall'] + X_train_input['Spa'] + X_train_input['VRDeck']\n",
    "X_test_input['Spendings'] = X_test_input['RoomService'] + X_test_input['FoodCourt'] + X_test_input['ShoppingMall'] + X_test_input['Spa'] + X_test_input['VRDeck']\n",
    "\n",
    "#get parameters for normalization --> avoid data leekage\n",
    "norm_paras = X_train_input.agg(['mean', 'std', 'median'])\n",
    "print(norm_paras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X, norm_paras=norm_paras):\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "    #extract y\n",
    "    if 'Transported' in X.columns:\n",
    "        y = X['Transported'].to_numpy()\n",
    "        X = X.drop(labels=\"Transported\", axis=1)\n",
    "    else:    y = None\n",
    "\n",
    "    length = X.shape[0]\n",
    "    print(f'sample size: {length}')\n",
    "\n",
    "    #get familiy size\n",
    "    X['Name'] = X['Name'].fillna('ukn')\n",
    "    X['Name'] = [name.split()[-1] for name in X['Name']]\n",
    "    X['Name'] = X['Name'].replace('ukn', 0)\n",
    "    name_occurence = X['Name'].value_counts(dropna=False)\n",
    "    X['FamilySize'] = [name_occurence[x]/20 for x in X['Name']] # divide by 20 to get values between 0 and 1\n",
    "    X['FamilySize'] = np.float32(X['FamilySize'])\n",
    "\n",
    "    #cabin details\n",
    "    X['Cabin'] = X['Cabin'].fillna('F/X/S') # fill missing values with most common value\n",
    "    X['Cabin'] = [x.split('/') for x in X['Cabin']]\n",
    "\n",
    "    X['C_deck'] = [0 for x in range(length)] #group B/C and rest --> binary\n",
    "    X['C_side'] = [0 for x in range(length)] # --> binary\n",
    "\n",
    "    for sample in range(length):\n",
    "        X['C_deck'][sample] = X['Cabin'].iloc[sample][0]\n",
    "        X['C_side'][sample] = X['Cabin'].iloc[sample][2]\n",
    "\n",
    "    X['C_deck'] = X['C_deck'].replace(['B', 'C'], 0)\n",
    "    X['C_deck'] = X['C_deck'].replace(['A', 'D', 'E', 'F', 'G', 'T'], 1)\n",
    "    X['C_side'] = X['C_side'].replace(['S'], 0)\n",
    "    X['C_side'] = X['C_side'].replace(['P'], 1)\n",
    "\n",
    "    #one-hot-encode categorical variables\n",
    "    X['HomePlanet'].fillna('Earth', inplace=True)\n",
    "    X['Destination'].fillna('TRAPPIST-1e', inplace=True)\n",
    "    X = pd.get_dummies(X, columns=['HomePlanet', 'Destination'])\n",
    "\n",
    "    #fill missing values for binary variables\n",
    "    binaries = ['CryoSleep', 'VIP', 'C_deck', 'C_side']\n",
    "    for col in binaries:\n",
    "        X[col].fillna(False, inplace=True)\n",
    "        X[col] = np.int32(X[col])\n",
    "\n",
    "    #normalize numerical variables and fill missing values\n",
    "    numerical = ['Age', 'Spendings', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    for col in numerical:\n",
    "        X[col].fillna(norm_paras[col]['median'], inplace=True)\n",
    "        X[col] = (X[col] - norm_paras[col]['mean']) / norm_paras[col]['std']\n",
    "        X[col] = np.float32(X[col])\n",
    "\n",
    "    #get id registering information\n",
    "    X['PassengerId'] = X['PassengerId'].str[:4].astype('float32') / 10000 # normalize\n",
    "\n",
    "    #drop columns\n",
    "    drops = ['Name', 'Cabin', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    X = X.drop(labels=drops, axis=1)\n",
    "\n",
    "    #change to numpy array\n",
    "    X_final = X.to_numpy()\n",
    "\n",
    "    #info\n",
    "    print(\"This is an extract of df after preprocessing:\")\n",
    "    print(f\"Shape X: {X_final.shape}, Shape y: {y.shape if y is not None else None}\")\n",
    "    print(X.info())\n",
    "\n",
    "    return X_final, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 6954\n",
      "This is an extract of df after preprocessing:\n",
      "Shape X: (6954, 10), Shape y: (6954,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6954 entries, 2333 to 7270\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   CryoSleep                  6954 non-null   int32  \n",
      " 1   Age                        6954 non-null   float32\n",
      " 2   VIP                        6954 non-null   int32  \n",
      " 3   Spendings                  6954 non-null   float32\n",
      " 4   HomePlanet_Earth           6954 non-null   uint8  \n",
      " 5   HomePlanet_Europa          6954 non-null   uint8  \n",
      " 6   HomePlanet_Mars            6954 non-null   uint8  \n",
      " 7   Destination_55 Cancri e    6954 non-null   uint8  \n",
      " 8   Destination_PSO J318.5-22  6954 non-null   uint8  \n",
      " 9   Destination_TRAPPIST-1e    6954 non-null   uint8  \n",
      "dtypes: float32(2), int32(2), uint8(6)\n",
      "memory usage: 461.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# preprocess train.csv\n",
    "X_train, y_train = preprocess(X_train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 1739\n",
      "This is an extract of df after preprocessing:\n",
      "Shape X: (1739, 10), Shape y: (1739,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1739 entries, 304 to 6093\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   CryoSleep                  1739 non-null   int32  \n",
      " 1   Age                        1739 non-null   float32\n",
      " 2   VIP                        1739 non-null   int32  \n",
      " 3   Spendings                  1739 non-null   float32\n",
      " 4   HomePlanet_Earth           1739 non-null   uint8  \n",
      " 5   HomePlanet_Europa          1739 non-null   uint8  \n",
      " 6   HomePlanet_Mars            1739 non-null   uint8  \n",
      " 7   Destination_55 Cancri e    1739 non-null   uint8  \n",
      " 8   Destination_PSO J318.5-22  1739 non-null   uint8  \n",
      " 9   Destination_TRAPPIST-1e    1739 non-null   uint8  \n",
      "dtypes: float32(2), int32(2), uint8(6)\n",
      "memory usage: 115.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = preprocess(X_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 4277\n",
      "This is an extract of df after preprocessing:\n",
      "Shape X: (4277, 10), Shape y: None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   CryoSleep                  4277 non-null   int32  \n",
      " 1   Age                        4277 non-null   float32\n",
      " 2   VIP                        4277 non-null   int32  \n",
      " 3   Spendings                  4277 non-null   float32\n",
      " 4   HomePlanet_Earth           4277 non-null   uint8  \n",
      " 5   HomePlanet_Europa          4277 non-null   uint8  \n",
      " 6   HomePlanet_Mars            4277 non-null   uint8  \n",
      " 7   Destination_55 Cancri e    4277 non-null   uint8  \n",
      " 8   Destination_PSO J318.5-22  4277 non-null   uint8  \n",
      " 9   Destination_TRAPPIST-1e    4277 non-null   uint8  \n",
      "dtypes: float32(2), int32(2), uint8(6)\n",
      "memory usage: 92.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# preprocess test.csv\n",
    "\n",
    "X_prediction = pd.read_csv('../data/raw/test.csv')\n",
    "X_prediction['Spendings'] = X_prediction['RoomService'] + X_prediction['FoodCourt'] + X_prediction['ShoppingMall'] + X_prediction['Spa'] + X_prediction['VRDeck']\n",
    "X_prediction, _ = preprocess(X_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  ndarray\n",
      "shape:  (1739, 10)\n",
      "strides:  (8, 13912)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  False\n",
      "fortran:  True\n",
      "data pointer: 0x55ab9eaa3930\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float64\n"
     ]
    }
   ],
   "source": [
    "np.info(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "# Save dataset --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare folder and info file for dataset versions\n",
    "\n",
    "version_ID = 'test'\n",
    "version_note = 'test'\n",
    "timestamp = time.strftime(\"on %Y_%m_%d at %H_%M\")\n",
    "\n",
    "overview = pd.read_csv('../data/preprocessed/dataset_overview.csv')\n",
    "\n",
    "if not os.path.exists(f'../data/preprocessed/{version_ID}'):\n",
    "        os.mkdir(f'../data/preprocessed/{version_ID}')\n",
    "\n",
    "#append to overview logs\n",
    "overview = overview.append({'version_ID': version_ID, 'version_note': version_note, 'timestamp': timestamp}, \n",
    "                                ignore_index=True)\n",
    "overview = overview[{'version_ID', 'version_note', 'timestamp'}]\n",
    "overview.drop_duplicates(inplace=True)\n",
    "overview.to_csv('../data/preprocessed/dataset_overview.csv')\n",
    "\n",
    "# save preprocessed data\n",
    "np.save(f'../data/preprocessed/{version_ID}/X_train.npy', X_train)\n",
    "np.save(f'../data/preprocessed/{version_ID}/X_test.npy', X_test)\n",
    "np.save(f'../data/preprocessed/{version_ID}/y_train.npy', y_train)\n",
    "np.save(f'../data/preprocessed/{version_ID}/y_test.npy', y_test)\n",
    "np.save(f'../data/preprocessed/{version_ID}/X_predict.npy', X_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>version_ID</th>\n",
       "      <th>version_note</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>v1_0</td>\n",
       "      <td>Initial version</td>\n",
       "      <td>on 2022_09_20 at 17_04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>v1_1</td>\n",
       "      <td>no more booleans</td>\n",
       "      <td>on 2022_09_21 at 21_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>v1_2</td>\n",
       "      <td>dtype 32s</td>\n",
       "      <td>on 2022_09_21 at 21_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>v1_2</td>\n",
       "      <td>dtype 32s</td>\n",
       "      <td>on 2022_09_21 at 21_51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>v1_3</td>\n",
       "      <td>name and cabin added</td>\n",
       "      <td>on 2022_09_22 at 04_08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>v1_4</td>\n",
       "      <td>name and cabin added</td>\n",
       "      <td>on 2022_09_22 at 04_43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>v1_4</td>\n",
       "      <td>name and cabin added</td>\n",
       "      <td>on 2022_09_22 at 04_57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>v1_4</td>\n",
       "      <td>name and cabin added</td>\n",
       "      <td>on 2022_09_22 at 05_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>v1_5</td>\n",
       "      <td>passenger and spendings added</td>\n",
       "      <td>on 2022_09_22 at 15_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>v2_0</td>\n",
       "      <td>reduced features</td>\n",
       "      <td>on 2022_09_22 at 15_29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 version_ID                   version_note  \\\n",
       "0           0       v1_0                Initial version   \n",
       "1           1       v1_1               no more booleans   \n",
       "2           2       v1_2                      dtype 32s   \n",
       "3           3       v1_2                      dtype 32s   \n",
       "4           4       v1_3           name and cabin added   \n",
       "5           5       v1_4           name and cabin added   \n",
       "6           6       v1_4           name and cabin added   \n",
       "7           7       v1_4           name and cabin added   \n",
       "8           8       v1_5  passenger and spendings added   \n",
       "9           9       v2_0               reduced features   \n",
       "\n",
       "                timestamp  \n",
       "0  on 2022_09_20 at 17_04  \n",
       "1  on 2022_09_21 at 21_10  \n",
       "2  on 2022_09_21 at 21_38  \n",
       "3  on 2022_09_21 at 21_51  \n",
       "4  on 2022_09_22 at 04_08  \n",
       "5  on 2022_09_22 at 04_43  \n",
       "6  on 2022_09_22 at 04_57  \n",
       "7  on 2022_09_22 at 05_02  \n",
       "8  on 2022_09_22 at 15_24  \n",
       "9  on 2022_09_22 at 15_29  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see overview of existant datasets\n",
    "\n",
    "overview = pd.read_csv('../data/preprocessed/dataset_overview.csv')\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# use to create new oversion and DELETE OLD VERSIONS #############\n",
    "\n",
    "# overview = pd.DataFrame(columns=['version_ID', 'version_note', 'timestamp'])\n",
    "# overview.to_csv('../data/preprocessed/dataset_overview.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59d600b4921a8892d280815dcd3c42f2a5d1bfe036a7914beca8a270877be602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
